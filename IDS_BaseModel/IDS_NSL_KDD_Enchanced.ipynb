{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro-markdown",
   "metadata": {},
   "source": [
    "# Network Intrusion Detection System\n",
    "\n",
    "This notebook demonstrates the original intrusion detection workflow along with an enhanced model. In addition to the existing XGBoost model, we add a stacking ensemble that combines XGBoost, Random Forest, and an MLP with Logistic Regression as the final estimator to improve overall accuracy and robustness :contentReference[oaicite:0]{index=0}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "plt.rcParams['figure.figsize'] = (10,6)\n",
    "\n",
    "# Load dataset (ensure 'KDDTest+.txt' is in the same directory)\n",
    "df = pd.read_csv('KDDTest+.txt')\n",
    "\n",
    "# Define column names\n",
    "columns = [\n",
    "    'duration', 'protocol_type', 'service', 'flag', 'src_bytes',\n",
    "    'dst_bytes', 'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins',\n",
    "    'logged_in', 'num_compromised', 'root_shell', 'su_attempted', 'num_root',\n",
    "    'num_file_creations', 'num_shells', 'num_access_files', 'num_outbound_cmds',\n",
    "    'is_host_login', 'is_guest_login', 'count', 'srv_count', 'serror_rate',\n",
    "    'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate',\n",
    "    'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count',\n",
    "    'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate',\n",
    "    'dst_host_srv_diff_host_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate',\n",
    "    'dst_host_rerror_rate', 'dst_host_srv_rerror_rate', 'attack', 'level'\n",
    "]\n",
    "\n",
    "df.columns = columns\n",
    "\n",
    "# Convert attack labels to binary: 'normal' vs 'attack'\n",
    "df['attack'] = df['attack'].apply(lambda x: 'normal' if x == 'normal' else 'attack')\n",
    "\n",
    "# Encode categorical features\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "for col in ['protocol_type', 'service', 'flag', 'attack']:\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop(['attack'], axis=1)\n",
    "y = df['attack']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=43)\n",
    "\n",
    "# Select top 15 features based on previous analysis\n",
    "top_features = [\n",
    "    'duration', 'protocol_type', 'service', 'flag', 'src_bytes',\n",
    "    'dst_bytes', 'wrong_fragment', 'hot', 'logged_in', 'num_compromised',\n",
    "    'count', 'srv_count', 'serror_rate', 'srv_serror_rate', 'rerror_rate'\n",
    "]\n",
    "\n",
    "X_train = X_train[top_features]\n",
    "X_test = X_test[top_features]\n",
    "\n",
    "# Standardize features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "original-model",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Metrics\n",
      "[[1228   24]\n",
      " [  17  986]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      1252\n",
      "           1       0.98      0.98      0.98      1003\n",
      "\n",
      "    accuracy                           0.98      2255\n",
      "   macro avg       0.98      0.98      0.98      2255\n",
      "weighted avg       0.98      0.98      0.98      2255\n",
      "\n",
      "\n",
      "Train Set Metrics\n",
      "[[11479   101]\n",
      " [   85  8623]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     11580\n",
      "           1       0.99      0.99      0.99      8708\n",
      "\n",
      "    accuracy                           0.99     20288\n",
      "   macro avg       0.99      0.99      0.99     20288\n",
      "weighted avg       0.99      0.99      0.99     20288\n",
      "\n",
      "XGBoost F1 Score: 0.980\n",
      "XGBoost Recall: 0.983\n",
      "XGBoost ROC AUC: 0.999\n"
     ]
    }
   ],
   "source": [
    "# Original Model: XGBoost classifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score, recall_score, roc_auc_score\n",
    "\n",
    "xgb_model = XGBClassifier(\n",
    "    colsample_bytree=0.5,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=6,\n",
    "    n_estimators=128,\n",
    "    subsample=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "def eval_metric(model, X_train, y_train, X_test, y_test):\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print('Test Set Metrics')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print('\\nTrain Set Metrics')\n",
    "    print(confusion_matrix(y_train, y_train_pred))\n",
    "    print(classification_report(y_train, y_train_pred))\n",
    "\n",
    "eval_metric(xgb_model, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Additional metrics for XGBoost\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "if hasattr(xgb_model, 'predict_proba'):\n",
    "    y_pred_proba = xgb_model.predict_proba(X_test)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_pred_proba[:, 1])\n",
    "    print('XGBoost F1 Score: {:.3f}'.format(f1))\n",
    "    print('XGBoost Recall: {:.3f}'.format(recall))\n",
    "    print('XGBoost ROC AUC: {:.3f}'.format(auc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stacked-model-intro",
   "metadata": {},
   "source": [
    "## Enhanced Model: Stacked Ensemble Classifier\n",
    "\n",
    "The following cell implements a stacking ensemble that combines three base models—XGBoost, Random Forest, and an MLP classifier—with Logistic Regression as the final estimator. This approach aims to improve the detection accuracy and robustness of the intrusion detection system :contentReference[oaicite:1]{index=1}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "stacked-model-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Metrics\n",
      "[[1228   24]\n",
      " [  17  986]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      1252\n",
      "           1       0.98      0.98      0.98      1003\n",
      "\n",
      "    accuracy                           0.98      2255\n",
      "   macro avg       0.98      0.98      0.98      2255\n",
      "weighted avg       0.98      0.98      0.98      2255\n",
      "\n",
      "\n",
      "Train Set Metrics\n",
      "[[11492    88]\n",
      " [  107  8601]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     11580\n",
      "           1       0.99      0.99      0.99      8708\n",
      "\n",
      "    accuracy                           0.99     20288\n",
      "   macro avg       0.99      0.99      0.99     20288\n",
      "weighted avg       0.99      0.99      0.99     20288\n",
      "\n",
      "Stacking Model F1 Score: 0.980\n",
      "Stacking Model Recall: 0.983\n",
      "Stacking Model ROC AUC: 0.999\n"
     ]
    }
   ],
   "source": [
    "# Build and evaluate the stacking ensemble model\n",
    "from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "estimators = [\n",
    "    ('xgb', XGBClassifier(\n",
    "            colsample_bytree=0.5,\n",
    "            learning_rate=0.1,\n",
    "            max_depth=6,\n",
    "            n_estimators=128,\n",
    "            subsample=0.8,\n",
    "            random_state=42\n",
    "         )),\n",
    "    ('rf', RandomForestClassifier(\n",
    "            n_estimators=100,\n",
    "            max_depth=10,\n",
    "            random_state=42\n",
    "         )),\n",
    "    ('mlp', MLPClassifier(\n",
    "            hidden_layer_sizes=(50, 50),\n",
    "            max_iter=300,\n",
    "            random_state=42\n",
    "         ))\n",
    "]\n",
    "\n",
    "final_estimator = LogisticRegression(random_state=42)\n",
    "\n",
    "stacking_model = StackingClassifier(\n",
    "    estimators=estimators,\n",
    "    final_estimator=final_estimator,\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "stacking_model.fit(X_train, y_train)\n",
    "\n",
    "eval_metric(stacking_model, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Additional metrics for the stacking model\n",
    "y_pred = stacking_model.predict(X_test)\n",
    "if hasattr(stacking_model, 'predict_proba'):\n",
    "    y_pred_proba = stacking_model.predict_proba(X_test)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_pred_proba[:, 1])\n",
    "    print('Stacking Model F1 Score: {:.3f}'.format(f1))\n",
    "    print('Stacking Model Recall: {:.3f}'.format(recall))\n",
    "    print('Stacking Model ROC AUC: {:.3f}'.format(auc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhanced model saved to ids_core/NSL-KDD/model_e.pkl\n"
     ]
    }
   ],
   "source": [
    "# Save the enhanced model to a pickle file\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Create the NSL-KDD directory if it doesn't exist\n",
    "os.makedirs('ids_core/NSL-KDD', exist_ok=True)\n",
    "\n",
    "# Path to save the model\n",
    "model_path = 'ids_core/NSL-KDD/model_e.pkl'\n",
    "\n",
    "# Save the stacking model which is our enhanced model\n",
    "with open(model_path, 'wb') as f:\n",
    "    pickle.dump(stacking_model, f)\n",
    "\n",
    "print(f\"Enhanced model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cysec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
